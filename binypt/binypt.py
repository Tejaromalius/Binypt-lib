# Copyright (c) 2023 ilia tayefi
#
# This software is released under the MIT License.
# https://opensource.org/licenses/MIT

import os
import re
import json
import time
import numpy as np
import pandas as pd
import datetime
import requests

from progress.bar import Bar
from concurrent.futures import ThreadPoolExecutor


def formatDateTimestamp(date: str, date_format: str):
    stripped_time = datetime.datetime.strptime(date, date_format).timestamp()
    return int(stripped_time)


def getValidatedFilePath(path: str, condition: bool):
    path = os.path.realpath(path)
    assert os.path.isfile(path) == condition and os.path.isdir(path) == condition, "path is not valid"
    return path


class Binypt:
    """
    Binypt: A Python Class for Cryptocurrency Data Retrieval and Processing

    Copyright (c) 2023 ilia tayefi


    License: MIT License

    Overview:

    The Binypt class is a Python implementation designed for retrieving and
    processing cryptocurrency market data from the Binance exchange. It provides
    functionality for downloading, processing, and storing historical price data for
    a specified cryptocurrency trading pair. The code is released under the MIT
    License, allowing users to modify and distribute it as needed.

    Features:

    1. Data Retrieval: The class leverages the Binance API to fetch historical price
       data for a given trading pair and time period.
    2. Data Processing: The retrieved data is processed and organized into a Pandas
       DataFrame for further analysis and manipulation.
    3. Batched Retrieval: To efficiently retrieve large sets of data, the class
       splits the desired time period into smaller batches and concurrently
       retrieves data for each batch.
    4. Progress Tracking: The progress of data retrieval is tracked using the
       progress.bar library, providing feedback on the status of data retrieval.
    5. Data Optimization: The retrieved data is optimized to ensure it only includes
       records within the desired time period, eliminating unnecessary data.
    6. Human-Readable Time: The class adds human-readable time representations to
       the DataFrame, making it easier to interpret time-related data.

    Class Initialization:

    The Binypt class can be initialized with the following parameters:

    - market_name (default: "BTCUSDT"): The trading pair symbol for which the data
      will be retrieved.
    - market_period (default: "THC"): The desired time interval for data retrieval
      (e.g., "12h" for 12-hour intervals).
    - starting_date (default: "2022-01-01/00:00:00"): The start date and time for
      data retrieval.
    - ending_date (default: "2023-01-01/00:00:00"): The end date and time for data
      retrieval.

    Class Methods:

    1. getData(): Returns the processed data as a Pandas DataFrame.
    2. update(): Initiates the data retrieval and processing workflow, updating the
       stored data.
    3. writeDataToPickle(file_path): Writes the processed data to a pickle file
       specified by file_path.

    Usage:

    To use the Binypt class, follow these steps:

    1. Initialize an instance of the class with desired parameters.
    2. Call the update() method to retrieve and process the data.
    3. Access the processed data using the getData() method or write it to a file
       using the writeData(file_path) method.

    ---

    *Generated by ChatGPT*
    """

    MILISECONDS = 1000
    DATE_FORMAT = "%d/%m/%Y-%H:%M:%S"
    METADATA_PATH = os.path.join(os.path.dirname(__file__), "metadata.json")

    def __init__(
        self,
        trading_pair: str,
        interval: str,
        starting_date: str,
        ending_date: str,
        output_path: str,
    ):
        self.trading_pair = trading_pair
        self.interval = interval
        self.starting_date = (
            formatDateTimestamp(starting_date, Binypt.DATE_FORMAT) * Binypt.MILISECONDS
        )
        self.ending_date = (
            formatDateTimestamp(ending_date, Binypt.DATE_FORMAT) * Binypt.MILISECONDS
        )
        self.output_path = getValidatedFilePath(output_path, False)
        self.metadata = self._importMetadata()

        self.data = pd.DataFrame(
            columns=self.metadata.get("chart_default_columns"), dtype=float
        )

        self.batched_timelines = list()
        self.total_timelines = 0

        self._update()

    def export(self):
        if re.search(r"\.(csv)$", self.output_path):
            self.data.to_csv(self.output_path)
        elif re.search(r"\.(excel)$", self.output_path):
            self.data.to_excel(self.output_path)
        elif re.search(r"\.(pickle)$", self.output_path):
            self.data.to_pickle(self.output_path)

    def _importMetadata(self):
        with open(Binypt.METADATA_PATH, "r") as metadata_file:
            return json.load(metadata_file)

    def _update(self):
        self._interpolateTimelines()
        self._downloadData()
        self._optimizeData()
        self._addHRTime()

    def _interpolateTimelines(self):
        jump = eval(self.metadata.get("intervals").get(self.interval))
        last_timeline = self.starting_date - jump

        batch = list()

        while last_timeline + jump < self.ending_date:
            if len(batch) == 1000:
                self.batched_timelines.append(batch)
                batch = list()

            batch.append([(last_timeline + jump), (last_timeline + jump * 2)])

            self.total_timelines += 1
            last_timeline += jump + 1

        if len(batch) != 0:
            self.batched_timelines.append(batch)

    def _downloadData(self):
        api_url = (
            "https://api.binance.com/api/v3/klines?symbol="
            + f"{self.trading_pair}&interval={self.interval}&limit=1000&"
            + "startTime={}&endTime={}"
        )
        bar = Bar(
            "Downloaded: ",
            max=self.total_timelines,
            suffix=" retrieved %(index)d/%(max)d",
        )

        def retreiveBatchedData(batch, batch_ix):
            while True:
                bar.goto(batch_ix * 1000)
                thread_pool = ThreadPoolExecutor()

                try:
                    urls = list(
                        api_url.format(timeline[0], timeline[1]) for timeline in batch
                    )
                    api_requests = list(
                        thread_pool.submit(lambda url: requests.get(url).json(), (url))
                        for url in urls
                    )

                    for request in api_requests:
                        bar.next()
                        while request._state == "RUNNING":
                            time.sleep(0.25)

                    return list(
                        request.result()
                        for request in api_requests
                        if len(request.result()) != 0
                    )

                except Exception:
                    continue

        for batch_ix, batch in enumerate(self.batched_timelines):
            binance_data = np.array(
                [
                    data
                    for batched_data in retreiveBatchedData(batch, batch_ix)
                    for data in batched_data
                ]
            )
            binance_data_df = pd.DataFrame(
                binance_data,
                columns=self.metadata.get("chart_default_columns"),
            ).astype(float)
            self.data = pd.concat([self.data, binance_data_df], ignore_index=True)

    def _optimizeData(self):
        end_point = 0

        for index in range(1, len(self.data)):
            if self.data.iloc[-index]["close_time"] < self.ending_date:
                end_point = len(self.data) - index
                break

        self.data = self.data.iloc[: end_point + 1]

    def _addHRTime(self):
        self.data["open_time_str"] = [
            datetime.datetime.fromtimestamp(time_record / Binypt.MILISECONDS)
            for time_record in self.data["open_time"]
        ]
        self.data["close_time_str"] = [
            datetime.datetime.fromtimestamp(time_record / Binypt.MILISECONDS)
            for time_record in self.data["close_time"]
        ]
